#!/usr/bin/env python3
"""
Service de synchronisation Gazelle ‚Üí Supabase.

Synchronise les donn√©es depuis l'API Gazelle vers les tables gazelle.* dans Supabase.
Ex√©cut√© quotidiennement (CRON job) pour maintenir les donn√©es √† jour.

Tables synchronis√©es (dans le sch√©ma public):
- gazelle_clients
- gazelle_contacts
- gazelle_pianos
- gazelle_appointments
- gazelle_timeline_entries

Usage:
    python3 modules/sync_gazelle/sync_to_supabase.py
"""

import sys
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
import requests

# Ajouter le projet au path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from dotenv import load_dotenv
load_dotenv()

from core.gazelle_api_client import GazelleAPIClient
from core.supabase_storage import SupabaseStorage


class GazelleToSupabaseSync:
    """Synchronise les donn√©es Gazelle vers Supabase."""

    def __init__(self):
        """Initialise le gestionnaire de synchronisation."""
        print("üîß Initialisation du service de synchronisation...")

        try:
            self.api_client = GazelleAPIClient()
            print("‚úÖ Client API Gazelle initialis√©")
        except Exception as e:
            print(f"‚ùå Erreur d'initialisation API Gazelle: {e}")
            raise

        try:
            self.storage = SupabaseStorage()
            print("‚úÖ Client Supabase initialis√©")
        except Exception as e:
            print(f"‚ùå Erreur d'initialisation Supabase: {e}")
            raise

        self.stats = {
            'clients': {'synced': 0, 'errors': 0},
            'contacts': {'synced': 0, 'errors': 0},
            'pianos': {'synced': 0, 'errors': 0},
            'appointments': {'synced': 0, 'errors': 0},
            'timeline': {'synced': 0, 'errors': 0}
        }

    def sync_clients(self) -> int:
        """
        Synchronise les clients depuis l'API vers Supabase.

        Returns:
            Nombre de clients synchronis√©s
        """
        print("\nüìã Synchronisation des clients...")

        try:
            # R√©cup√©rer clients depuis API Gazelle
            api_clients = self.api_client.get_clients(limit=1000)

            if not api_clients:
                print("‚ö†Ô∏è  Aucun client r√©cup√©r√© depuis l'API")
                return 0

            print(f"üì• {len(api_clients)} clients r√©cup√©r√©s depuis l'API")

            for client_data in api_clients:
                try:
                    # Extraire donn√©es du client
                    external_id = client_data.get('id')
                    company_name_raw = client_data.get('companyName')
                    company_name = company_name_raw.strip() if company_name_raw else ''
                    status = client_data.get('status', 'active')
                    tags = client_data.get('tags', [])

                    # Contact par d√©faut
                    default_contact = client_data.get('defaultContact', {})

                    # Si CompanyName vide, utiliser nom du contact
                    if not company_name and default_contact:
                        first_name_raw = default_contact.get('firstName')
                        last_name_raw = default_contact.get('lastName')
                        first_name = first_name_raw.strip() if first_name_raw else ''
                        last_name = last_name_raw.strip() if last_name_raw else ''
                        company_name = f"{first_name} {last_name}".strip()

                    if not company_name:
                        print(f"‚ö†Ô∏è  Client {external_id} ignor√© (nom vide)")
                        self.stats['clients']['errors'] += 1
                        continue

                    # Email, t√©l√©phone, adresse du contact
                    email = None
                    phone = None
                    address = None
                    city = None
                    postal_code = None

                    if default_contact:
                        default_email = default_contact.get('defaultEmail', {})
                        if default_email:
                            email = default_email.get('email')

                        default_phone = default_contact.get('defaultPhone', {})
                        if default_phone:
                            phone = default_phone.get('phoneNumber')

                        default_location = default_contact.get('defaultLocation', {})
                        if default_location:
                            # Construire l'adresse compl√®te depuis street1/street2
                            street1 = default_location.get('street1', '')
                            street2 = default_location.get('street2', '')
                            if street1 and street2:
                                address = f"{street1}, {street2}"
                            elif street1:
                                address = street1
                            elif street2:
                                address = street2

                            city = default_location.get('municipality')
                            postal_code = default_location.get('postalCode')

                    # Pr√©parer donn√©es pour Supabase
                    client_record = {
                        'external_id': external_id,
                        'company_name': company_name,
                        'status': status,
                        'tags': tags,
                        'email': email,
                        'phone': phone,
                        'address': address,
                        'city': city,
                        'postal_code': postal_code,
                        'created_at': client_data.get('createdAt'),
                        'updated_at': datetime.now().isoformat()
                    }

                    # UPSERT dans Supabase (via REST API)
                    url = f"{self.storage.api_url}/gazelle_clients"
                    headers = self.storage._get_headers()
                    headers["Prefer"] = "resolution=merge-duplicates"

                    import requests
                    response = requests.post(url, headers=headers, json=client_record)

                    if response.status_code in [200, 201]:
                        self.stats['clients']['synced'] += 1
                    elif response.status_code == 409:
                        # 409 = Conflict (d√©j√† synchronis√©, normal avec UPSERT)
                        self.stats['clients']['synced'] += 1
                    else:
                        print(f"‚ùå Erreur UPSERT client {external_id}: {response.status_code}")
                        self.stats['clients']['errors'] += 1

                except Exception as e:
                    print(f"‚ùå Erreur client {client_data.get('id', 'unknown')}: {e}")
                    self.stats['clients']['errors'] += 1
                    continue

            print(f"‚úÖ {self.stats['clients']['synced']} clients synchronis√©s")
            return self.stats['clients']['synced']

        except Exception as e:
            print(f"‚ùå Erreur lors de la synchronisation des clients: {e}")
            raise

    def sync_contacts(self) -> int:
        """
        Synchronise les contacts depuis l'API vers Supabase.

        Note: Dans Gazelle, les contacts sont des personnes individuelles
        associ√©es aux clients (entit√©s qui paient).

        Returns:
            Nombre de contacts synchronis√©s
        """
        print("\nüë• Synchronisation des contacts...")

        try:
            # R√©cup√©rer contacts depuis API Gazelle
            api_contacts = self.api_client.get_contacts(limit=2000)
            print(f"üì• {len(api_contacts)} contacts r√©cup√©r√©s depuis l'API")

            # Initialiser stats
            self.stats['contacts'] = {'total': len(api_contacts), 'synced': 0, 'errors': 0}

            # Synchroniser chaque contact
            for contact_data in api_contacts:
                try:
                    external_id = contact_data.get('id')
                    if not external_id:
                        print(f"‚ö†Ô∏è  Contact sans ID ignor√©")
                        continue

                    # Extraire les donn√©es du contact
                    first_name = contact_data.get('firstName')
                    last_name = contact_data.get('lastName')
                    company_name = contact_data.get('companyName')

                    # Email et t√©l√©phone (peuvent √™tre None)
                    default_email = contact_data.get('defaultEmail', {})
                    email = default_email.get('email') if default_email else None

                    default_phone = contact_data.get('defaultPhone', {})
                    phone = default_phone.get('phoneNumber') if default_phone else None

                    # Localisation (peut √™tre None)
                    default_location = contact_data.get('defaultLocation', {})
                    city = default_location.get('municipality') if default_location else None
                    province = default_location.get('province') if default_location else None
                    postal_code = default_location.get('postalCode') if default_location else None
                    street_address = default_location.get('streetAddress') if default_location else None

                    # Client associ√© (peut √™tre None)
                    client_data = contact_data.get('client', {})
                    client_id = client_data.get('id') if client_data else None
                    client_company_name = client_data.get('companyName') if client_data else None

                    # Construire le payload pour Supabase
                    # Note: Le sch√©ma de la table gazelle_contacts a seulement:
                    # external_id, client_external_id, first_name, last_name, email, phone, is_default, created_at, updated_at
                    contact_payload = {
                        'external_id': external_id,
                        'client_external_id': client_id,
                        'first_name': first_name,
                        'last_name': last_name,
                        'email': email,
                        'phone': phone,
                        'is_default': True,  # C'est le defaultContact du client
                        'created_at': contact_data.get('createdAt'),
                        'updated_at': contact_data.get('updatedAt')
                    }

                    # UPSERT dans Supabase via REST API
                    url = f"{self.storage.api_url}/gazelle_contacts"
                    headers = self.storage._get_headers()
                    headers['Prefer'] = 'resolution=merge-duplicates'

                    response = requests.post(url, json=contact_payload, headers=headers)

                    if response.status_code in [200, 201]:
                        self.stats['contacts']['synced'] += 1
                    elif response.status_code == 409:
                        # 409 = Conflict (d√©j√† synchronis√©, normal avec UPSERT)
                        self.stats['contacts']['synced'] += 1
                    else:
                        print(f"‚ùå Erreur UPSERT contact {external_id}: {response.status_code}")
                        self.stats['contacts']['errors'] += 1

                except Exception as e:
                    print(f"‚ùå Erreur contact {contact_data.get('id', 'unknown')}: {e}")
                    self.stats['contacts']['errors'] += 1
                    continue

            print(f"‚úÖ {self.stats['contacts']['synced']} contacts synchronis√©s")
            return self.stats['contacts']['synced']

        except Exception as e:
            print(f"‚ùå Erreur lors de la synchronisation des contacts: {e}")
            raise

    def sync_pianos(self) -> int:
        """
        Synchronise les pianos depuis l'API vers Supabase.

        Returns:
            Nombre de pianos synchronis√©s
        """
        print("\nüéπ Synchronisation des pianos...")

        try:
            api_pianos = self.api_client.get_pianos(limit=1000)

            if not api_pianos:
                print("‚ö†Ô∏è  Aucun piano r√©cup√©r√© depuis l'API")
                return 0

            print(f"üì• {len(api_pianos)} pianos r√©cup√©r√©s depuis l'API")

            for piano_data in api_pianos:
                try:
                    external_id = piano_data.get('id')
                    client_obj = piano_data.get('client', {})
                    client_id = client_obj.get('id') if client_obj else None
                    make = piano_data.get('make', '')
                    model = piano_data.get('model', '')
                    serial_number = piano_data.get('serialNumber')
                    piano_type = piano_data.get('type', 'upright')
                    year = piano_data.get('year')
                    location = piano_data.get('location', '')
                    notes = piano_data.get('notes', '')

                    # Nouveaux champs Dampp-Chaser (si disponibles dans l'API)
                    dampp_chaser_installed = piano_data.get('damppChaserInstalled', False)
                    dampp_chaser_humidistat_model = piano_data.get('damppChaserHumidistatModel')
                    dampp_chaser_mfg_date = piano_data.get('damppChaserMfgDate')

                    piano_record = {
                        'external_id': external_id,
                        'client_external_id': client_id,
                        'make': make,
                        'model': model,
                        'serial_number': serial_number,
                        'type': piano_type,
                        'year': year,
                        'location': location,
                        'notes': notes,
                        'dampp_chaser_installed': dampp_chaser_installed,
                        'dampp_chaser_humidistat_model': dampp_chaser_humidistat_model,
                        'dampp_chaser_mfg_date': dampp_chaser_mfg_date,
                        'updated_at': datetime.now().isoformat()
                    }

                    # UPSERT
                    url = f"{self.storage.api_url}/gazelle_pianos"
                    headers = self.storage._get_headers()
                    headers["Prefer"] = "resolution=merge-duplicates"

                    import requests
                    response = requests.post(url, headers=headers, json=piano_record)

                    if response.status_code in [200, 201]:
                        self.stats['pianos']['synced'] += 1
                    elif response.status_code == 409:
                        # 409 = Conflict (d√©j√† synchronis√©, normal avec UPSERT)
                        self.stats['pianos']['synced'] += 1
                    else:
                        print(f"‚ùå Erreur UPSERT piano {external_id}: {response.status_code}")
                        self.stats['pianos']['errors'] += 1

                except Exception as e:
                    print(f"‚ùå Erreur piano {piano_data.get('id', 'unknown')}: {e}")
                    self.stats['pianos']['errors'] += 1
                    continue

            print(f"‚úÖ {self.stats['pianos']['synced']} pianos synchronis√©s")
            return self.stats['pianos']['synced']

        except Exception as e:
            print(f"‚ùå Erreur lors de la synchronisation des pianos: {e}")
            raise

    def sync_appointments(self, start_date_override: Optional[str] = None, force_historical: bool = False) -> int:
        """
        Synchronise les rendez-vous depuis Gazelle vers Supabase.

        LOGIQUE INTELLIGENTE:
        1. Premier import: R√©cup√®re TOUT depuis 2017 (historique complet)
        2. Syncs suivants: Seulement les 7 derniers jours (incr√©mental)

        Utilise un marqueur 'appointments_historical_import_done' dans system_settings.

        Args:
            start_date_override: Date de d√©but explicite (YYYY-MM-DD). Si fourni, force cette date.
            force_historical: Si True, force un import historique complet m√™me si d√©j√† fait.

        Returns:
            Nombre de rendez-vous synchronis√©s
        """
        print("\nüìÖ Synchronisation des rendez-vous...")

        # D√©terminer si c'est le premier import ou un sync incr√©mental
        historical_done = False

        if not force_historical and not start_date_override:
            try:
                # V√©rifier si l'import historique a d√©j√† √©t√© fait
                url = f"{self.storage.api_url}/system_settings?key=eq.appointments_historical_import_done&select=value"
                response = requests.get(url, headers=self.storage._get_headers())

                if response.status_code == 200:
                    data = response.json()
                    if data and len(data) > 0:
                        historical_done = data[0]['value'] == 'true'
            except Exception as e:
                print(f"‚ö†Ô∏è  Impossible de v√©rifier le marqueur d'import: {e}")

        # D√©terminer la date de d√©but
        if start_date_override:
            # Override manuel
            effective_start_date = start_date_override
            print(f"üéØ Mode manuel: import depuis {effective_start_date}")
        elif force_historical or not historical_done:
            # Premier import: tout depuis 2017
            effective_start_date = '2017-01-01'
            print(f"üèõÔ∏è  IMPORT HISTORIQUE COMPLET depuis {effective_start_date}")
            print("   (Cette op√©ration peut prendre plusieurs minutes...)")
        else:
            # Sync incr√©mental: seulement les 7 derniers jours
            effective_start_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
            print(f"üîÑ Sync incr√©mental: derniers 7 jours (depuis {effective_start_date})")

        try:
            api_appointments = self.api_client.get_appointments(
                limit=None,
                start_date_override=effective_start_date
            )

            if not api_appointments:
                print("‚ö†Ô∏è  Aucun rendez-vous r√©cup√©r√© depuis l'API")
                return 0

            print(f"üì• {len(api_appointments)} rendez-vous r√©cup√©r√©s depuis l'API")

            for appt_data in api_appointments:
                try:
                    external_id = appt_data.get('id')

                    # Client
                    client_obj = appt_data.get('client', {})
                    client_id = client_obj.get('id') if client_obj else None

                    # Titre et notes
                    title = appt_data.get('title', '')
                    notes_raw = appt_data.get('notes', '')
                    description = notes_raw

                    # Date et heure depuis start
                    start_time = appt_data.get('start')
                    appointment_date = None
                    appointment_time = None

                    if start_time:
                        try:
                            from datetime import datetime as dt

                            # CORRECT: Gazelle retourne du VRAI UTC (le 'Z' est fiable)
                            # L'API affiche 09:15 √† l'√©cran (Toronto) et retourne 14:15Z dans l'API (UTC)
                            # On stocke tel quel, sans double conversion.
                            dt_utc = dt.fromisoformat(start_time)

                            appointment_date = dt_utc.date().isoformat()
                            appointment_time = dt_utc.time().isoformat()
                        except Exception as e:
                            print(f"‚ö†Ô∏è Erreur conversion heure '{start_time}': {e}")
                            pass

                    # Dur√©e en minutes
                    duration_minutes = appt_data.get('duration')

                    # Status
                    status = appt_data.get('status', 'scheduled')

                    # Technicien (depuis user.id - maintenant disponible avec V4 query)
                    user_obj = appt_data.get('user', {})
                    technicien = user_obj.get('id') if user_obj else None

                    # Location (pas disponible simplement)
                    location = ''

                    # Notes
                    notes = notes_raw if notes_raw else title

                    # Nouveaux champs V4
                    event_type = appt_data.get('type', 'APPOINTMENT')
                    is_all_day = appt_data.get('isAllDay', False)
                    confirmed_by_client = appt_data.get('confirmedByClient', False)
                    source = appt_data.get('source', 'MANUAL')
                    travel_mode = appt_data.get('travelMode', '')

                    # CreatedBy
                    created_by_obj = appt_data.get('createdBy', {})
                    created_by_user_id = created_by_obj.get('id') if created_by_obj else None

                    # Piano (extraction V4 - ligne 264)
                    piano_id = None
                    piano_nodes = (appt_data.get('allEventPianos') or {}).get('nodes', [])
                    if piano_nodes and len(piano_nodes) > 0:
                        first_piano_node = piano_nodes[0]
                        if first_piano_node and first_piano_node.get('piano'):
                            piano_id = first_piano_node['piano'].get('id')

                    appointment_record = {
                        'external_id': external_id,
                        'client_external_id': client_id,
                        'title': title,
                        'description': description,
                        'appointment_date': appointment_date,
                        'appointment_time': appointment_time,
                        'duration_minutes': duration_minutes,
                        'status': status,
                        'technicien': technicien,
                        'location': location,
                        'notes': notes,
                        'created_at': start_time,  # Utiliser start comme created_at
                        'updated_at': datetime.now().isoformat()
                    }

                    # UPSERT
                    url = f"{self.storage.api_url}/gazelle_appointments"
                    headers = self.storage._get_headers()
                    headers["Prefer"] = "resolution=merge-duplicates"

                    import requests
                    response = requests.post(url, headers=headers, json=appointment_record)

                    if response.status_code in [200, 201]:
                        self.stats['appointments']['synced'] += 1
                    elif response.status_code == 409:
                        # 409 = Conflict (d√©j√† synchronis√©, normal avec UPSERT)
                        self.stats['appointments']['synced'] += 1
                    else:
                        print(f"‚ùå Erreur UPSERT appointment {external_id}: {response.status_code} - {response.text}")
                        self.stats['appointments']['errors'] += 1

                except Exception as e:
                    print(f"‚ùå Erreur appointment {appt_data.get('id', 'unknown')}: {e}")
                    self.stats['appointments']['errors'] += 1

            print(f"‚úÖ {self.stats['appointments']['synced']} rendez-vous synchronis√©s")

            # Marquer l'import historique comme termin√© si c'√©tait un import complet
            if not start_date_override and (force_historical or not historical_done):
                try:
                    print("\nüíæ Marquage de l'import historique comme termin√©...")
                    url = f"{self.storage.api_url}/system_settings"
                    headers = self.storage._get_headers()
                    headers["Prefer"] = "resolution=merge-duplicates"

                    response = requests.post(url, headers=headers, json={
                        'key': 'appointments_historical_import_done',
                        'value': 'true'
                    })

                    if response.status_code in [200, 201]:
                        print("‚úÖ Marqueur 'appointments_historical_import_done' enregistr√©")
                        print("   ‚Üí Les prochains syncs seront incr√©mentaux (7 derniers jours)")
                    else:
                        print(f"‚ö†Ô∏è  Erreur lors de l'enregistrement du marqueur: {response.status_code}")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Impossible d'enregistrer le marqueur: {e}")

            return self.stats['appointments']['synced']

        except Exception as e:
            print(f"‚ùå Erreur lors de la synchronisation des rendez-vous: {e}")
            raise

    def sync_timeline_entries(self) -> int:
        """
        Synchronise les timeline entries depuis Gazelle vers Supabase (FEN√äTRE 15 JOURS).

        Strat√©gie simplifi√©e:
        1. R√©cup√®re les entr√©es de l'API (tri√©es du plus r√©cent au plus ancien)
        2. Arr√™te d√®s qu'une entr√©e a plus de 15 jours
        3. Utilise UPSERT pour mettre √† jour les entr√©es existantes

        Returns:
            Nombre d'entr√©es synchronis√©es
        """
        print("\nüìñ Synchronisation timeline (fen√™tre glissante 30 jours)...")

        try:
            from datetime import datetime, timedelta
            from zoneinfo import ZoneInfo

            # Date de cutoff: maintenant - 30 jours (√©tendu pour capturer services de fin d√©cembre)
            cutoff_date = datetime.now() - timedelta(days=30)
            cutoff_iso = cutoff_date.isoformat()

            print(f"üìÖ Fen√™tre de synchronisation: entr√©es depuis {cutoff_iso}")

            # Utiliser le filtre API pour r√©cup√©rer SEULEMENT les 30 derniers jours
            # Cela √©vite de t√©l√©charger 100,000+ entr√©es inutiles √† chaque sync
            api_entries = self.api_client.get_timeline_entries(
                since_date=cutoff_iso,
                limit=None
            )

            if not api_entries:
                print("‚ö†Ô∏è  Aucune timeline entry r√©cup√©r√©e depuis l'API")
                return 0

            print(f"üì• {len(api_entries)} timeline entries re√ßues de l'API")

            synced_count = 0
            stopped_by_age = False

            for entry_data in api_entries:
                try:
                    # CRITICAL: V√©rifier si l'entr√©e est trop ancienne (>30 jours)
                    occurred_at = entry_data.get('occurredAt')

                    if occurred_at:
                        # Parser la date (format ISO)
                        try:
                            entry_date = datetime.fromisoformat(occurred_at.replace('Z', '+00:00'))
                            # Rendre aware si naive
                            if entry_date.tzinfo is None:
                                entry_date = entry_date.replace(tzinfo=ZoneInfo('UTC'))

                            # Comparer avec cutoff (rendre cutoff aware aussi)
                            cutoff_aware = cutoff_date.replace(tzinfo=ZoneInfo('UTC'))

                            if entry_date < cutoff_aware:
                                # SKIP cette entr√©e (trop vieille), mais continuer la sync
                                continue
                        except Exception as e:
                            print(f"‚ö†Ô∏è  Erreur parsing date '{occurred_at}': {e}")

                    external_id = entry_data.get('id')

                    # Client
                    client_obj = entry_data.get('client', {})
                    client_id = client_obj.get('id') if client_obj else None

                    # Piano
                    piano_obj = entry_data.get('piano', {})
                    piano_id = piano_obj.get('id') if piano_obj else None

                    # Invoice et Estimate
                    invoice_obj = entry_data.get('invoice', {})
                    invoice_id = invoice_obj.get('id') if invoice_obj else None

                    estimate_obj = entry_data.get('estimate', {})
                    estimate_id = estimate_obj.get('id') if estimate_obj else None

                    # User (technicien)
                    user_obj = entry_data.get('user', {})
                    user_id = user_obj.get('id') if user_obj else None

                    # Donn√©es de l'entr√©e
                    entry_type = entry_data.get('type', 'UNKNOWN')
                    # IMPORTANT: GraphQL retourne summary/comment, pas title/details
                    title = entry_data.get('summary', '')
                    details = entry_data.get('comment', '')

                    # DEBUG: Logger les SERVICE_ENTRY_MANUAL du 26-28 d√©c
                    if entry_type == 'SERVICE_ENTRY_MANUAL' and occurred_at and occurred_at >= '2025-12-26':
                        print(f"üîç SERVICE_ENTRY_MANUAL: {occurred_at} | {(details or title)[:50]}")

                    timeline_record = {
                        'external_id': external_id,
                        'client_id': client_id,
                        'piano_id': piano_id,
                        'invoice_id': invoice_id,
                        'estimate_id': estimate_id,
                        'user_id': user_id,
                        'occurred_at': occurred_at,
                        'entry_type': entry_type,
                        'title': title,
                        'description': details  # La colonne s'appelle 'description' pas 'details'
                        # Note: createdAt/updatedAt n'existent pas dans PrivateTimelineEntry
                    }

                    # UPSERT
                    url = f"{self.storage.api_url}/gazelle_timeline_entries"
                    headers = self.storage._get_headers()
                    headers["Prefer"] = "resolution=merge-duplicates"

                    response = requests.post(url, headers=headers, json=timeline_record)

                    # DEBUG: Logger r√©ponse compl√®te pour services du 26-28 d√©c
                    if entry_type == 'SERVICE_ENTRY_MANUAL' and occurred_at and occurred_at >= '2025-12-26':
                        print(f"  üì§ POST Response: {response.status_code}")
                        print(f"     Body: {response.text[:300]}")

                    if response.status_code in [200, 201]:
                        self.stats['timeline']['synced'] += 1
                        synced_count += 1
                    elif response.status_code == 409:
                        # 409 peut √™tre un succ√®s (merge) OU une erreur - v√©rifier la r√©ponse
                        print(f"‚ö†Ô∏è  409 Conflict pour {external_id}: {response.text[:200]}")
                        self.stats['timeline']['synced'] += 1
                        synced_count += 1
                    else:
                        print(f"‚ùå Erreur UPSERT timeline {external_id}: {response.status_code}")
                        print(f"   Response: {response.text[:200]}")
                        self.stats['timeline']['errors'] += 1

                except Exception as e:
                    print(f"‚ùå Erreur timeline entry {entry_data.get('id', 'unknown')}: {e}")
                    self.stats['timeline']['errors'] += 1
                    continue

            # Affichage final
            if stopped_by_age:
                print(f"‚úÖ {synced_count} timeline entries synchronis√©es (fen√™tre 15 jours)")
            else:
                print(f"‚úÖ {synced_count} timeline entries synchronis√©es (toutes < 15 jours)")

            return synced_count

        except Exception as e:
            print(f"‚ùå Erreur lors de la synchronisation des timeline entries: {e}")
            raise

    def sync_users(self) -> int:
        """
        Synchronise les techniciens (users) depuis l'API Gazelle vers Supabase.

        Returns:
            Nombre de techniciens synchronis√©s
        """
        print("\nüë• Synchronisation des techniciens (users)...")

        try:
            # R√©cup√©rer les users depuis l'API Gazelle
            users_data = self.api_client.get_users()

            if not users_data:
                print("‚ö†Ô∏è  Aucun utilisateur r√©cup√©r√© depuis l'API")
                return 0

            print(f"üì• {len(users_data)} utilisateurs r√©cup√©r√©s depuis l'API")

            synced_count = 0

            for user in users_data:
                try:
                    user_id = user.get('id')
                    if not user_id:
                        continue

                    # Pr√©parer les donn√©es pour Supabase
                    user_record = {
                        'id': user_id,  # Gazelle ID (ex: usr_ofYggsCDt2JAVeNP)
                        'external_id': user.get('externalId'),
                        'first_name': user.get('firstName'),
                        'last_name': user.get('lastName'),
                        'email': user.get('email'),
                        'phone': user.get('phone'),
                        'role': user.get('role'),
                        'updated_at': datetime.now().isoformat()
                    }

                    # UPSERT via REST API
                    url = f"{self.storage.api_url}/users"
                    headers = self.storage._get_headers()
                    headers["Prefer"] = "resolution=merge-duplicates"

                    response = requests.post(url, headers=headers, json=user_record)

                    if response.status_code in [200, 201]:
                        synced_count += 1
                    else:
                        print(f"‚ö†Ô∏è  Erreur sync user {user_id}: HTTP {response.status_code} - {response.text[:200]}")

                except Exception as e:
                    print(f"‚ùå Erreur sync user {user.get('id', 'unknown')}: {e}")
                    continue

            print(f"‚úÖ {synced_count} techniciens synchronis√©s")
            return synced_count

        except Exception as e:
            print(f"‚ùå Erreur lors de la synchronisation des users: {e}")
            raise

    def sync_all(self) -> Dict[str, Any]:
        """
        Synchronise toutes les tables Gazelle vers Supabase.

        Returns:
            Dictionnaire de statistiques
        """
        print("=" * 70)
        print("üîÑ SYNCHRONISATION GAZELLE ‚Üí SUPABASE")
        print("=" * 70)
        print(f"üìÖ Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 70)

        start_time = datetime.now()

        try:
            # Synchroniser dans l'ordre de d√©pendance
            # 0. Users/Techniciens (requis pour timeline entries FK)
            self.sync_users()

            # 1. Clients (requis pour pianos, contacts, etc.)
            self.sync_clients()

            # 2. Contacts (personnes associ√©es aux clients)
            self.sync_contacts()

            # 3. Pianos (d√©pend de clients)
            self.sync_pianos()

            # 4. Appointments (utilise maintenant allEventsBatched de V4)
            self.sync_appointments()

            # 5. Timeline entries (notes techniques)
            self.sync_timeline_entries()

            # R√©sum√©
            duration = (datetime.now() - start_time).total_seconds()

            print("\n" + "=" * 70)
            print("‚úÖ SYNCHRONISATION TERMIN√âE")
            print("=" * 70)
            print(f"‚è±Ô∏è  Dur√©e: {duration:.2f}s")
            print("\nüìä R√©sum√©:")
            print(f"   ‚Ä¢ Clients:      {self.stats['clients']['synced']:4d} synchronis√©s, {self.stats['clients']['errors']:2d} erreurs")
            print(f"   ‚Ä¢ Contacts:     {self.stats['contacts']['synced']:4d} synchronis√©s, {self.stats['contacts']['errors']:2d} erreurs")
            print(f"   ‚Ä¢ Pianos:       {self.stats['pianos']['synced']:4d} synchronis√©s, {self.stats['pianos']['errors']:2d} erreurs")
            print(f"   ‚Ä¢ RV:           {self.stats['appointments']['synced']:4d} synchronis√©s, {self.stats['appointments']['errors']:2d} erreurs")
            print(f"   ‚Ä¢ Timeline:     {self.stats['timeline']['synced']:4d} synchronis√©s, {self.stats['timeline']['errors']:2d} erreurs")
            print("=" * 70)

            return {
                'success': True,
                'duration_seconds': duration,
                'stats': self.stats,
                'timestamp': datetime.now().isoformat()
            }

        except Exception as e:
            print(f"\n‚ùå ERREUR FATALE: {e}")
            import traceback
            traceback.print_exc()

            return {
                'success': False,
                'error': str(e),
                'stats': self.stats,
                'timestamp': datetime.now().isoformat()
            }


def main():
    """Point d'entr√©e principal du script."""
    try:
        sync_manager = GazelleToSupabaseSync()
        result = sync_manager.sync_all()

        # Exit code selon succ√®s
        exit_code = 0 if result['success'] else 1
        sys.exit(exit_code)

    except Exception as e:
        print(f"\n‚ùå Erreur fatale: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
