"""
G√©n√©ration des rapports Timeline v5 depuis Supabase vers Google Sheets.

Principes:
- Lecture Supabase (tables gazelle_timeline_entries, gazelle_clients, maintenance_alerts*)
- Cat√©gorisation par onglet (UQAM / Vincent / Place des Arts / Alertes Maintenance)
- √âcriture dans le Google Sheet "Rapport Timeline v5" (append par d√©faut)
- Conversion horaire en America/Toronto (Montr√©al)

(*) La table des alertes peut √™tre nomm√©e maintenance_alerts ou gazelle_maintenance_alerts.
"""

from __future__ import annotations

import os
from datetime import datetime, timezone
from typing import Dict, List, Optional
from zoneinfo import ZoneInfo

import gspread
import requests
from google.auth.exceptions import DefaultCredentialsError
from gspread.exceptions import SpreadsheetNotFound, WorksheetNotFound

from core.supabase_storage import SupabaseStorage

MONTREAL_TZ = ZoneInfo("America/Montreal")
# Google Sheet: https://docs.google.com/spreadsheets/d/1ZZsMrIT0BEwHKQ6-BKGzFoXR3k99zCEzixp0tsRKUj8
SHEET_NAME = "Rapport Timeline de l'assistant v5"

CLIENT_KEYWORDS = {
    "UQAM": ["uqam"],
    "Vincent": ["vincent"],
    "Place des Arts": ["place des arts"],
}

# Mots-cl√©s pour l'onglet Alertes Maintenance (notes ou description)
# Bas√©s sur core/humidity_alert_detector.py - Filtrage strict pour alertes r√©elles
MAINTENANCE_KEYWORDS = [
    # Housse retir√©e (cover_removed)
    "housse retir√©e",
    "housse retiree",
    "housse enlev√©e",
    "housse enlevee",
    "sans housse",
    "pas de housse",
    
    # Dampp-Chaser / Alimentation (dampp_chaser)
    "dampp chaser d√©branch√©",
    "dampp-chaser d√©branch√©",
    "dampp chaser off",
    "dampp chaser √©teint",
    "dampp chaser ne fonctionne",
    "dampp-chaser ne fonctionne",
    "pls d√©branch√©",
    "syst√®me d√©branch√©",
    "systeme debranche",
    "d√©branch√©",
    "debranche",
    "rebranch√©",
    "rebranche",
    "rallonge",
    "besoin rallonge",
    
    # R√©servoir (reservoir)
    "r√©servoir vide",
    "reservoir vide",
    "tank empty",
    "r√©servoir √† remplir",
    
    # Environnement critique (environment) - SP√âCIFIQUE
    "fen√™tre ouverte",
    "fenetre ouverte",
    "temp√©rature trop basse",
    "trop froid",
    "humidit√© trop √©lev√©e",
    "humidit√© tr√®s basse",
    "conditions inad√©quates",
    
    # Humidit√© extr√™me (high/low_humidity)
    "humidit√© haute",
    "humidit√© √©lev√©e",
    "tr√®s humide",
    "trop humide",
    "humidit√© basse",
    "humidit√© faible",
    "tr√®s sec",
    "trop sec",
]

# Clients institutionnels pour les Alertes Maintenance
INSTITUTIONAL_CLIENTS = ["uqam", "vincent", "place des arts"]

MAINTENANCE_TABLES_CANDIDATES = [
    "maintenance_alerts",
    "gazelle_maintenance_alerts",
]

# Colonnes pour l'onglet Demandes PdA
PDA_REQUESTS_HEADERS = [
    "DateDemande",
    "DateRV",
    "Heure",
    "Salle",
    "Piano",
    "Artiste",
    "Service",
    "Demandeur",
    "Statut",
    "Notes"
]


class ServiceReports:
    """Service principal pour g√©n√©rer les rapports Timeline v5."""

    def __init__(
        self,
        storage: Optional[SupabaseStorage] = None,
        sheet_name: str = SHEET_NAME,
        credentials_path: Optional[str] = None,
    ) -> None:
        self.storage = storage or SupabaseStorage()
        self.sheet_name = sheet_name
        
        # v6: Utiliser IdentityManager pour charger depuis Supabase ou fallback v5
        if credentials_path:
            # Si un chemin est fourni explicitement, l'utiliser
            self.credentials_path = credentials_path
        else:
            # Sinon, utiliser IdentityManager (v6) avec fallback v5
            try:
                from v6_foundation.identity_manager import IdentityManager
                identity_manager = IdentityManager(storage=self.storage)
                self.credentials_path = identity_manager.get_google_credentials_path()
                # Garder une r√©f√©rence pour le nettoyage si n√©cessaire
                self._identity_manager = identity_manager
            except (ImportError, FileNotFoundError) as e:
                # Fallback v5: Variable d'environnement
                print(f"‚ö†Ô∏è  IdentityManager non disponible, utilisation du fallback v5: {e}")
                self.credentials_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
                self._identity_manager = None
        
        if not self.credentials_path:
            raise FileNotFoundError(
                "GOOGLE_APPLICATION_CREDENTIALS manquant. "
                "V√©rifiez Supabase system_settings['GOOGLE_SHEETS_JSON'] "
                "ou la variable d'environnement GOOGLE_APPLICATION_CREDENTIALS"
            )
        if not os.path.exists(self.credentials_path):
            raise FileNotFoundError(f"Fichier de service account introuvable: {self.credentials_path}")
        self.gc = self._init_gspread_client(self.credentials_path)

    @staticmethod
    def _init_gspread_client(credentials_path: str) -> gspread.Client:
        """Initialise le client gspread via service account."""
        try:
            return gspread.service_account(filename=credentials_path)
        except DefaultCredentialsError as e:
            raise RuntimeError(f"Impossible d'initialiser le client Google: {e}")

    # ------------------------------------------------------------------
    # R√©cup√©ration des donn√©es Supabase
    # ------------------------------------------------------------------
    def _fetch_clients_map(self) -> Dict[str, str]:
        """Retourne un mapping external_id -> company_name."""
        url = f"{self.storage.api_url}/gazelle_clients"
        params = {"select": "external_id,company_name"}
        resp = requests.get(url, headers=self.storage._get_headers(), params=params, timeout=20)
        if resp.status_code != 200:
            print(f"‚ö†Ô∏è Impossible de r√©cup√©rer les clients ({resp.status_code}): {resp.text}")
            return {}
        data = resp.json() or []
        return {item.get("external_id"): item.get("company_name") for item in data if item.get("external_id")}

    def _fetch_timeline_entries(self, since: Optional[datetime]) -> List[Dict]:
        """R√©cup√®re les timeline entries avec infos piano et user (avec pagination)."""
        from supabase import create_client

        supabase = create_client(self.storage.supabase_url, self.storage.supabase_key)

        all_entries = []
        page_size = 1000
        offset = 0
        
        print(f"üì• R√©cup√©ration des timeline entries (pagination {page_size})...")

        while True:
            # Construire la requ√™te avec relations
            query = supabase.table('gazelle_timeline_entries').select('''
                external_id,
                description,
                title,
                entry_date,
                occurred_at,
                entity_id,
                entity_type,
                event_type,
                entry_type,
                piano_id,
                user_id,
                piano:gazelle_pianos(
                    make,
                    model,
                    serial_number,
                    type,
                    year,
                    location,
                    client_external_id
                ),
                user:users(
                    first_name,
                    last_name
                )
            ''') \
            .in_('entry_type', ['SERVICE_ENTRY_MANUAL', 'PIANO_MEASUREMENT']) \
            .order('occurred_at', desc=True) \
            .range(offset, offset + page_size - 1)

            if since:
                query = query.gte('occurred_at', since.isoformat())

            result = query.execute()
            batch = result.data or []
            
            if not batch:
                break
            
            all_entries.extend(batch)
            print(f"   Page {offset//page_size + 1}: {len(batch)} entr√©es (total: {len(all_entries)})")
            
            if len(batch) < page_size:
                break
            
            offset += page_size

        print(f"‚úÖ Total r√©cup√©r√©: {len(all_entries)} entr√©es\n")
        return all_entries

    def _fetch_maintenance_alerts(self) -> List[Dict]:
        """Tente de r√©cup√©rer les alertes de maintenance depuis Supabase."""
        headers = self.storage._get_headers()
        for table_name in MAINTENANCE_TABLES_CANDIDATES:
            url = f"{self.storage.api_url}/{table_name}"
            params = {"select": "id,client_id,piano_id,date_observation,description,notes,is_resolved,created_at"}
            try:
                resp = requests.get(url, headers=headers, params=params, timeout=20)
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur requ√™te {table_name}: {e}")
                continue
            if resp.status_code == 200:
                data = resp.json() or []
                if data:
                    return data
        return []

    def _fetch_pda_requests(self) -> List[Dict]:
        """R√©cup√®re les demandes Place des Arts depuis Supabase."""
        from supabase import create_client

        try:
            supabase = create_client(self.storage.supabase_url, self.storage.supabase_key)
            result = supabase.table('place_des_arts_requests').select('*').order('appointment_date', desc=True).execute()
            data = result.data or []
            print(f"üì• {len(data)} demandes Place des Arts r√©cup√©r√©es")
            return data
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur r√©cup√©ration demandes PdA: {e}")
            return []

    # ------------------------------------------------------------------
    # Utilitaires
    # ------------------------------------------------------------------
    def get_last_run(self) -> Optional[datetime]:
        """Retourne la derni√®re ex√©cution stock√©e dans system_settings."""
        try:
            last_run_value = self.storage.get_system_setting("reports_timeline_last_run")
            if not last_run_value:
                return None
            return datetime.fromisoformat(str(last_run_value))
        except Exception:
            return None

    @staticmethod
    def _to_montreal_date(date_str: str) -> str:
        """Convertit une date ISO en AAAA-MM-JJ fuseau Montr√©al."""
        if not date_str:
            return ""
        try:
            cleaned = date_str.replace("Z", "+00:00")
            dt = datetime.fromisoformat(cleaned)
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=timezone.utc)
            return dt.astimezone(MONTREAL_TZ).strftime("%Y-%m-%d")
        except Exception:
            return date_str

    @staticmethod
    def _normalize_text(*parts: Optional[str]) -> str:
        return " ".join([p or "" for p in parts]).lower()
    
    @staticmethod
    def _format_piano_info(make: str, model: str, serial: str, piano_type: str, year: str) -> str:
        """
        Formate les infos du piano en une seule description lisible.
        Exemple: "Steinway Model D #123456 (Grand, 1995)"
        """
        parts = []
        
        # Marque et mod√®le
        if make and model:
            parts.append(f"{make} {model}")
        elif make:
            parts.append(make)
        elif model:
            parts.append(model)
        
        # Num√©ro de s√©rie
        if serial:
            parts.append(f"#{serial}")
        
        # Type et ann√©e entre parenth√®ses
        extras = []
        if piano_type:
            extras.append(piano_type)
        if year:
            extras.append(year)
        
        if extras:
            parts.append(f"({', '.join(extras)})")
        
        return " ".join(parts) if parts else ""

    def _categories_for_entry(self, client_name: str, description: str) -> List[str]:
        """D√©termine les onglets cibles pour une entr√©e."""
        target_tabs: List[str] = []
        text = self._normalize_text(client_name, description)

        for tab, keywords in CLIENT_KEYWORDS.items():
            if any(keyword in text for keyword in keywords):
                target_tabs.append(tab)

        # Alertes Maintenance: SEULEMENT pour clients institutionnels avec mots-cl√©s sp√©cifiques
        is_institutional = any(inst_keyword in text for inst_keyword in INSTITUTIONAL_CLIENTS)
        has_maintenance_issue = any(keyword in text for keyword in MAINTENANCE_KEYWORDS)
        
        if is_institutional and has_maintenance_issue:
            target_tabs.append("Alertes Maintenance")

        return target_tabs

    # ------------------------------------------------------------------
    # Google Sheets helpers
    # ------------------------------------------------------------------
    def _get_workbook(self):
        """Ouvre le spreadsheet (le cr√©e si besoin)."""
        try:
            return self.gc.open(self.sheet_name)
        except SpreadsheetNotFound:
            # Cr√©ation si le compte a les droits Drive
            workbook = self.gc.create(self.sheet_name)
            return workbook

    @staticmethod
    def _get_or_create_ws(workbook, title: str):
        try:
            return workbook.worksheet(title)
        except WorksheetNotFound:
            return workbook.add_worksheet(title=title, rows=200, cols=10)

    @staticmethod
    def _ensure_headers(ws, headers: Optional[List[str]] = None):
        """Ajoute l'en-t√™te si la feuille est vide."""
        try:
            if not ws.acell("A1").value:
                if headers is None:
                    headers = [
                        "DateEvenement",
                        "TypeEvenement",
                        "Description",
                        "Piano",  # Colonne unique regroupant marque, mod√®le, s√©rie, type, ann√©e
                        "Local",
                        "Technicien",
                        "MesureHumidite"
                    ]
                # Construire la plage dynamiquement (A1:X1 o√π X d√©pend du nombre de colonnes)
                end_col = chr(ord('A') + len(headers) - 1)
                ws.update(f"A1:{end_col}1", [headers])
        except Exception as e:
            print(f"‚ö†Ô∏è Impossible d'√©crire l'en-t√™te sur {ws.title}: {e}")

    @staticmethod
    def _create_row_signature(row: List[str]) -> str:
        """
        Cr√©e une signature unique pour une ligne bas√©e sur DateEvenement + Description.
        Utilis√© pour d√©tecter les doublons.
        """
        date_event = (row[0] if len(row) > 0 else "").strip()
        description = (row[2] if len(row) > 2 else "").strip()
        # Tronquer la description √† 200 caract√®res pour √©viter les probl√®mes de comparaison
        description_truncated = description[:200]
        return f"{date_event}|||{description_truncated}"

    @staticmethod
    def _get_existing_row_signatures(ws) -> set:
        """
        R√©cup√®re les signatures des lignes existantes dans le Google Sheet.
        Retourne un set de signatures pour la d√©tection de doublons.
        """
        try:
            all_values = ws.get_all_values()
            if len(all_values) <= 1:  # Seulement l'en-t√™te ou vide
                return set()

            # Ignorer l'en-t√™te (premi√®re ligne)
            existing_signatures = set()
            for row in all_values[1:]:  # Skip header
                if row and any(cell.strip() for cell in row):  # Ignorer les lignes vides
                    signature = ServiceReports._create_row_signature(row)
                    existing_signatures.add(signature)

            return existing_signatures
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lecture signatures existantes pour {ws.title}: {e}")
            return set()

    @staticmethod
    def _filter_duplicate_rows(rows: List[List[str]], existing_signatures: set) -> List[List[str]]:
        """
        Filtre les lignes en double en comparant avec les signatures existantes.
        Retourne uniquement les nouvelles lignes qui n'existent pas d√©j√†.
        """
        new_rows = []
        duplicate_count = 0

        for row in rows:
            signature = ServiceReports._create_row_signature(row)
            if signature not in existing_signatures:
                new_rows.append(row)
            else:
                duplicate_count += 1

        if duplicate_count > 0:
            print(f"   ‚ö†Ô∏è {duplicate_count} ligne(s) en double ignor√©e(s)")

        return new_rows

    # ------------------------------------------------------------------
    # Construction et √©criture des rapports
    # ------------------------------------------------------------------
    @staticmethod
    def _simplify_measurement(description: str) -> str:
        """Simplifie la description d'une mesure (ex: 'Piano measurement taken: 20¬∞C, 42%' -> '20¬∞C, 42%')."""
        if not description:
            return ""
        # Format anglais
        if "Piano measurement taken:" in description:
            return description.split(":", 1)[1].strip()
        # Format fran√ßais
        elif "Mesure du piano prise :" in description or "Mesure du piano prise:" in description:
            return description.split(":", 1)[1].strip()
        # D√©j√† simplifi√© (contient ¬∞ et %)
        elif "¬∞" in description and "%" in description:
            return description.strip()
        return ""

    @staticmethod
    def _extract_measurements_from_text(text: str) -> str:
        """
        Extrait temp√©rature et humidit√© d'un texte avec d√©tection intelligente de toutes les variantes.

        Formats d√©tect√©s:
        - 20C, 33% | 20c, 33% | 20¬∞C, 33% | 20¬∞, 33% | 20 C, 33%
        - Temp√©rature ambiante 23¬∞ Celsius, humidit√© relative 35%
        - 68F, 40% (Fahrenheit)

        Retourne format normalis√©: "20¬∞, 33%" ou "33%" si seulement humidit√©
        """
        import re

        if not text:
            return ""

        # PATTERN 1: D√©tecter format compact direct "20C, 33%" ou "20¬∞, 33%"
        # Cherche: nombre + [C|c|¬∞|¬∞ C|¬∞C|F|f] + optionnel(virgule|espace) + nombre + %
        compact_pattern = r'(\d+)\s*([CcFf¬∞](?:\s*[CcFf])?)\s*,?\s*(\d+)\s*%'
        compact_match = re.search(compact_pattern, text)

        if compact_match:
            temp_value = compact_match.group(1)
            temp_unit = compact_match.group(2).strip().upper()
            humidity_value = compact_match.group(3)

            # Normaliser l'unit√© (tout convertir en ¬∞)
            return f"{temp_value}¬∞, {humidity_value}%"

        # PATTERN 2: Chercher temp√©rature seule avec diff√©rentes variantes
        # 23¬∞, 23¬∞ Celsius, 23¬∞C, 23C, 23c, 23 C, 23 degr√©s, 68F, etc.
        temp_patterns = [
            r'(\d+)\s*¬∞\s*(?:Celsius|C)?',  # 23¬∞, 23¬∞ Celsius, 23¬∞C
            r'(\d+)\s*[CcFf](?:\s|,|$)',     # 23C, 23c, 23F (suivi d'espace, virgule ou fin)
            r'(\d+)\s+degr√©s?\s*(?:Celsius)?', # 23 degr√©s, 23 degr√© Celsius
        ]

        temp_match = None
        for pattern in temp_patterns:
            temp_match = re.search(pattern, text, re.IGNORECASE)
            if temp_match:
                break

        # PATTERN 3: Chercher humidit√©
        # Priorit√© 1: Avec mot-cl√© "humidit√©/humidity"
        humidity_match = re.search(r'(?:humidit√©|humidity)[^0-9]*(\d+)\s*%', text, re.IGNORECASE)

        # Priorit√© 2: Juste un nombre suivi de %
        if not humidity_match:
            all_percent = re.findall(r'(\d+)\s*%', text)
            if all_percent:
                # Prendre le premier % trouv√©
                humidity_match = type('obj', (object,), {'group': lambda self, x: all_percent[0]})()

        # COMBINER les r√©sultats
        if temp_match and humidity_match:
            temp = temp_match.group(1)
            humidity = humidity_match.group(1) if hasattr(humidity_match, 'group') else all_percent[0]
            return f"{temp}¬∞, {humidity}%"
        elif temp_match:
            return f"{temp_match.group(1)}¬∞"
        elif humidity_match:
            humidity = humidity_match.group(1) if hasattr(humidity_match, 'group') else (all_percent[0] if 'all_percent' in locals() else "")
            return f"{humidity}%" if humidity else ""

        return ""

    def _build_rows_from_timeline(
        self,
        entries: List[Dict],
        clients_map: Dict[str, str],
    ) -> Dict[str, List[List[str]]]:
        from datetime import datetime
        import pytz

        rows_by_tab = {tab: [] for tab in CLIENT_KEYWORDS.keys()}
        rows_by_tab["Alertes Maintenance"] = []

        # D√©dupliquer les entr√©es : certaines ont √©t√© import√©es avec tle_ ET tme_ (deux IDs diff√©rents)
        # Strat√©gie : Garder tme_ (pr√©fixe plus r√©cent) et √©liminer tle_ si doublon
        # NOTE: On utilise SEULEMENT (date, description) sans piano_id car les doublons peuvent avoir des piano_id diff√©rents
        from collections import defaultdict
        
        # Grouper par signature (date, description SEULEMENT)
        by_signature = defaultdict(list)
        for entry in entries:
            occurred_at = entry.get("occurred_at") or entry.get("entry_date") or ""
            desc = entry.get("description") or entry.get("title") or ""
            date_str = occurred_at[:10] if occurred_at and len(occurred_at) >= 10 else "no_date"
            signature = f"{date_str}|||{desc[:200]}"
            by_signature[signature].append(entry)
        
        # Pour chaque signature, garder SEULEMENT l'entr√©e tme_ si elle existe, sinon garder la premi√®re
        deduplicated_entries = []
        for signature, group in by_signature.items():
            if len(group) == 1:
                # Pas de doublon
                deduplicated_entries.append(group[0])
            else:
                # Doublon : prioriser tme_ sur tle_
                tme_entries = [e for e in group if e.get("external_id", "").startswith("tme_")]
                if tme_entries:
                    deduplicated_entries.append(tme_entries[0])  # Garder le premier tme_
                else:
                    deduplicated_entries.append(group[0])  # Fallback : garder le premier
        
        print(f"üîß D√©duplication: {len(entries)} ‚Üí {len(deduplicated_entries)} entr√©es ({len(entries) - len(deduplicated_entries)} doublons √©limin√©s)")

        # S√©parer services et mesures
        services = []
        measurements = []

        for entry in deduplicated_entries:
            entry_type = entry.get("entry_type") or ""
            if entry_type == "SERVICE_ENTRY_MANUAL":
                services.append(entry)
            elif entry_type == "PIANO_MEASUREMENT":
                measurements.append(entry)

        # Grouper les mesures par (piano_id, date_only)
        measurements_by_piano_date = {}
        for measurement in measurements:
            piano_id = measurement.get("piano_id")
            date_raw = measurement.get("occurred_at") or measurement.get("entry_date", "")

            if not piano_id or not date_raw:
                continue

            # Convertir en date Montreal (sans heure)
            try:
                cleaned = date_raw.replace("Z", "+00:00")
                dt = datetime.fromisoformat(cleaned)
                if dt.tzinfo is None:
                    dt = dt.replace(tzinfo=pytz.utc)
                date_only = dt.astimezone(MONTREAL_TZ).date()
            except:
                continue

            key = (piano_id, date_only)
            if key not in measurements_by_piano_date:
                measurements_by_piano_date[key] = []

            # Simplifier la description
            desc = measurement.get("title") or measurement.get("description") or ""
            simplified = self._simplify_measurement(desc)
            if simplified:
                measurements_by_piano_date[key].append(simplified)

        # Traiter les services
        service_keys = set()
        for service in services:
            piano = service.get("piano") or {}
            entity_id = service.get("entity_id")
            client_id = piano.get("client_external_id") or entity_id
            client_name = clients_map.get(client_id, "Inconnu")

            date_raw = service.get("occurred_at") or service.get("entry_date", "")
            entry_date = self._to_montreal_date(date_raw)

            # Date_only pour lookup mesures
            try:
                cleaned = date_raw.replace("Z", "+00:00")
                dt = datetime.fromisoformat(cleaned)
                if dt.tzinfo is None:
                    dt = dt.replace(tzinfo=pytz.utc)
                date_only = dt.astimezone(MONTREAL_TZ).date()
            except:
                date_only = None

            description = service.get("title") or service.get("description") or ""

            marque = piano.get("make") or ""
            modele = piano.get("model") or ""
            numero_serie = piano.get("serial_number") or ""
            type_piano = piano.get("type") or ""
            annee = str(piano.get("year") or "")
            local = piano.get("location") or ""

            user = service.get("user") or {}
            first_name = user.get("first_name") or ""
            last_name = user.get("last_name") or ""
            technicien = f"{first_name} {last_name}".strip() if (first_name or last_name) else ""

            # R√©cup√©rer mesures du m√™me piano + m√™me jour
            piano_id = service.get("piano_id")
            mesure_humidite = ""

            # 1. Parser mesures depuis la description du service
            extracted_from_text = self._extract_measurements_from_text(description)

            # 2. R√©cup√©rer mesures des PIANO_MEASUREMENT entries
            if piano_id and date_only:
                key = (piano_id, date_only)
                service_keys.add(key)
                measures = measurements_by_piano_date.get(key, [])

                # 3. Combiner intelligemment (√©viter doublons)
                # Priorit√©: mesure compl√®te (temp + humidit√©) > humidit√© seule
                all_measures = []

                if extracted_from_text:
                    all_measures.append(extracted_from_text)
                if measures:
                    all_measures.extend(measures)

                # D√©dupliquer et prioriser les mesures compl√®tes
                if all_measures:
                    # S√©parer mesures compl√®tes (avec ¬∞) et humidit√© seule (juste %)
                    complete_measures = [m for m in all_measures if "¬∞" in m]
                    humidity_only = [m for m in all_measures if "¬∞" not in m and "%" in m]

                    # Priorit√© 1: Si on a une mesure compl√®te, l'utiliser (prendre la premi√®re)
                    if complete_measures:
                        mesure_humidite = complete_measures[0]
                    # Priorit√© 2: Sinon, prendre l'humidit√© seule
                    elif humidity_only:
                        mesure_humidite = humidity_only[0]

            # Formater la description du piano en une seule colonne
            piano_info = self._format_piano_info(marque, modele, numero_serie, type_piano, annee)
            
            row = [
                entry_date,          # DateEvenement
                "Service",           # TypeEvenement
                description,         # Description
                piano_info,          # Piano (regroup√©)
                local,               # Local
                technicien,          # Technicien
                mesure_humidite      # MesureHumidite
            ]

            for tab in self._categories_for_entry(client_name, description):
                rows_by_tab[tab].append(row)

        # Ajouter mesures orphelines (sans service le m√™me jour)
        for (piano_id, date_only), measures in measurements_by_piano_date.items():
            key = (piano_id, date_only)
            if key in service_keys:
                continue  # D√©j√† associ√©e √† un service

            # Trouver l'entry pour r√©cup√©rer les infos
            measurement_entry = None
            for m in measurements:
                if m.get("piano_id") == piano_id:
                    try:
                        date_raw = m.get("occurred_at") or m.get("entry_date", "")
                        cleaned = date_raw.replace("Z", "+00:00")
                        dt = datetime.fromisoformat(cleaned)
                        if dt.tzinfo is None:
                            dt = dt.replace(tzinfo=pytz.utc)
                        m_date_only = dt.astimezone(MONTREAL_TZ).date()
                        if m_date_only == date_only:
                            measurement_entry = m
                            break
                    except:
                        continue

            if not measurement_entry:
                continue

            piano = measurement_entry.get("piano") or {}
            entity_id = measurement_entry.get("entity_id")
            client_id = piano.get("client_external_id") or entity_id
            client_name = clients_map.get(client_id, "Inconnu")

            date_raw = measurement_entry.get("occurred_at") or measurement_entry.get("entry_date", "")
            entry_date = self._to_montreal_date(date_raw)

            marque = piano.get("make") or ""
            modele = piano.get("model") or ""
            numero_serie = piano.get("serial_number") or ""
            type_piano = piano.get("type") or ""
            annee = str(piano.get("year") or "")
            local = piano.get("location") or ""

            user = measurement_entry.get("user") or {}
            first_name = user.get("first_name") or ""
            last_name = user.get("last_name") or ""
            technicien = f"{first_name} {last_name}".strip() if (first_name or last_name) else ""

            # D√©dupliquer et prioriser les mesures compl√®tes (m√™me logique que services)
            complete_measures = [m for m in measures if "¬∞" in m]
            humidity_only = [m for m in measures if "¬∞" not in m and "%" in m]

            if complete_measures:
                mesure_humidite = complete_measures[0]
            elif humidity_only:
                mesure_humidite = humidity_only[0]
            else:
                mesure_humidite = ""

            # Formater la description du piano en une seule colonne
            piano_info = self._format_piano_info(marque, modele, numero_serie, type_piano, annee)
            
            row = [
                entry_date,          # DateEvenement
                "Mesure",            # TypeEvenement (orpheline)
                "",                  # Description vide
                piano_info,          # Piano (regroup√©)
                local,               # Local
                technicien,          # Technicien
                mesure_humidite      # MesureHumidite
            ]

            for tab in self._categories_for_entry(client_name, ""):
                rows_by_tab[tab].append(row)

        return rows_by_tab

    @staticmethod
    def _extract_date_only(date_str: str) -> str:
        """Extrait la date (YYYY-MM-DD) sans conversion de timezone.

        Pour les demandes PdA, les dates sont des dates calendrier,
        pas des instants pr√©cis - donc on ne convertit pas la timezone.
        """
        if not date_str:
            return ""
        # Prendre juste les 10 premiers caract√®res (YYYY-MM-DD)
        return date_str[:10] if len(date_str) >= 10 else date_str

    def _build_rows_from_pda_requests(self, requests: List[Dict]) -> List[List[str]]:
        """Construit les lignes pour l'onglet Demandes PdA."""
        rows: List[List[str]] = []

        for req in requests:
            # Extraire les dates SANS conversion timezone (dates calendrier)
            request_date = self._extract_date_only(req.get("request_date") or req.get("created_at") or "")
            appointment_date = self._extract_date_only(req.get("appointment_date") or "")

            row = [
                request_date,                           # DateDemande
                appointment_date,                       # DateRV
                req.get("time") or "",                  # Heure
                req.get("room") or "",                  # Salle
                req.get("piano") or "",                 # Piano
                req.get("for_who") or "",               # Artiste
                req.get("service") or "",               # Service
                req.get("requester") or "",             # Demandeur
                req.get("status") or "",                # Statut
                (req.get("notes") or "")[:200]          # Notes (tronqu√©es)
            ]
            rows.append(row)

        return rows

    def _build_rows_from_alerts(
        self,
        alerts: List[Dict],
        clients_map: Dict[str, str],
    ) -> List[List[str]]:
        rows: List[List[str]] = []
        for alert in alerts:
            client_id = alert.get("client_id") or alert.get("clientId")
            client_name = clients_map.get(client_id, "Inconnu")
            date_str = (
                alert.get("date_observation")
                or alert.get("dateObservation")
                or alert.get("created_at")
                or alert.get("createdAt")
                or ""
            )
            description = alert.get("description") or alert.get("notes") or ""

            # Filtrer: seulement clients institutionnels avec mots-cl√©s de maintenance
            text = self._normalize_text(client_name, description)
            is_institutional = any(inst_keyword in text for inst_keyword in INSTITUTIONAL_CLIENTS)
            has_maintenance_issue = any(keyword in text for keyword in MAINTENANCE_KEYWORDS)
            
            if not (is_institutional and has_maintenance_issue):
                continue  # Skip cette alerte

            # Construire ligne avec 7 colonnes (alertes n'ont pas d'infos piano)
            row = [
                self._to_montreal_date(date_str),  # DateEvenement
                "Alerte",                          # TypeEvenement
                description,                       # Description
                "",                                # Piano (vide pour les alertes)
                "",                                # Local
                "",                                # Technicien
                ""                                 # MesureHumidite
            ]
            rows.append(row)
        return rows

    def generate_reports(self, since: Optional[datetime] = None, append: bool = True) -> Dict[str, int]:
        """
        G√©n√®re/append les rapports vers Google Sheets.

        Args:
            since: datetime √† partir de laquelle r√©cup√©rer les timeline entries
            append: si False, efface et r√©√©crit les onglets
        """
        clients_map = self._fetch_clients_map()
        timeline_entries = self._fetch_timeline_entries(since=since)

        # NOTE: On n'utilise PLUS la table humidity_alerts pour √©viter les doublons.
        # Les alertes sont d√©j√† d√©tect√©es depuis les timeline entries via les mots-cl√©s.
        # alerts = self._fetch_maintenance_alerts()

        rows_by_tab = self._build_rows_from_timeline(timeline_entries, clients_map)

        # D√âSACTIV√â: √âvite les doublons car les alertes sont d√©j√† dans timeline entries
        # alert_rows = self._build_rows_from_alerts(alerts, clients_map) if alerts else []
        # if alert_rows:
        #     rows_by_tab["Alertes Maintenance"].extend(alert_rows)

        # R√©cup√©rer les demandes Place des Arts
        pda_requests = self._fetch_pda_requests()
        pda_rows = self._build_rows_from_pda_requests(pda_requests)

        workbook = self._get_workbook()
        counts: Dict[str, int] = {}

        for tab, rows in rows_by_tab.items():
            ws = self._get_or_create_ws(workbook, tab)
            if not append:
                try:
                    ws.clear()
                except Exception as e:
                    print(f"‚ö†Ô∏è Impossible de nettoyer l'onglet {tab}: {e}")
            self._ensure_headers(ws)

            if rows:
                # Filtrer les doublons si append=True
                if append:
                    existing_signatures = self._get_existing_row_signatures(ws)
                    rows = self._filter_duplicate_rows(rows, existing_signatures)

                if rows:
                    try:
                        # Trier par date d√©croissante (plus r√©centes en premier)
                        # La colonne 0 est DateEvenement (format YYYY-MM-DD)
                        rows_sorted = sorted(rows, key=lambda r: r[0] if r[0] else "", reverse=True)

                        # Ins√©rer apr√®s l'en-t√™te (ligne 2) pour garder les plus r√©centes en haut
                        ws.insert_rows(rows_sorted, row=2, value_input_option="RAW")
                        counts[tab] = len(rows_sorted)
                    except Exception as e:
                        print(f"‚ùå Erreur insert {tab}: {e}")
                        counts[tab] = 0
                else:
                    counts[tab] = 0
            else:
                counts[tab] = 0

        # === ONGLET DEMANDES PDA ===
        pda_tab = "Demandes PdA"
        ws_pda = self._get_or_create_ws(workbook, pda_tab)
        if not append:
            try:
                ws_pda.clear()
            except Exception as e:
                print(f"‚ö†Ô∏è Impossible de nettoyer l'onglet {pda_tab}: {e}")

        # En-t√™tes sp√©cifiques pour les demandes PdA
        self._ensure_headers(ws_pda, PDA_REQUESTS_HEADERS)

        if pda_rows:
            # Filtrer les doublons si append=True
            if append:
                existing_signatures = self._get_existing_row_signatures(ws_pda)
                # Pour PdA, la signature est DateRV + Salle + Artiste (colonnes 1, 3, 5)
                pda_rows_filtered = []
                for row in pda_rows:
                    sig = f"{row[1]}|||{row[3]}|||{row[5]}"  # DateRV + Salle + Artiste
                    if sig not in existing_signatures:
                        pda_rows_filtered.append(row)
                    existing_signatures.add(sig)
                pda_rows = pda_rows_filtered

            if pda_rows:
                try:
                    # Trier par DateRV d√©croissante (colonne 1)
                    rows_sorted = sorted(pda_rows, key=lambda r: r[1] if r[1] else "", reverse=True)
                    ws_pda.insert_rows(rows_sorted, row=2, value_input_option="RAW")
                    counts[pda_tab] = len(rows_sorted)
                    print(f"‚úÖ {len(rows_sorted)} demandes PdA ajout√©es √† l'onglet '{pda_tab}'")
                except Exception as e:
                    print(f"‚ùå Erreur insert {pda_tab}: {e}")
                    counts[pda_tab] = 0
            else:
                counts[pda_tab] = 0
        else:
            counts[pda_tab] = 0

        # Sauvegarder la date de derni√®re g√©n√©ration pour √©viter les doublons
        try:
            self.storage.save_system_setting(
                "reports_timeline_last_run",
                datetime.now(timezone.utc).isoformat(),
            )
        except Exception as e:
            print(f"‚ö†Ô∏è Impossible de sauvegarder reports_timeline_last_run: {e}")

        return counts


def run_reports(since: Optional[datetime] = None, append: bool = True) -> Dict[str, int]:
    """Entrypoint utilitaire."""
    service = ServiceReports()
    return service.generate_reports(since=since, append=append)
