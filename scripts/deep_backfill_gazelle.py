#!/usr/bin/env python3
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘             RESTAURATION HISTORIQUE PROFONDE GAZELLE (2016-2026)           â•‘
â•‘                     Backfill complet avec sÃ©curitÃ© anti-effacement         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ce script rÃ©cupÃ¨re TOUT l'historique Gazelle depuis 2016 et le synchronise
vers Supabase en mode UPSERT sÃ©curisÃ© (jamais de suppression).

StratÃ©gie:
- Pagination Relay avec curseur (first: 100, after)
- UPSERT strict avec on_conflict (jamais de DELETE)
- Progression annÃ©e par annÃ©e avec rÃ©sumÃ©s
- Gestion d'erreurs robuste

Usage:
    python3 scripts/deep_backfill_gazelle.py [--start-year 2016] [--end-year 2026]
"""

import sys
from pathlib import Path

# Ajouter le projet au path
sys.path.insert(0, str(Path(__file__).parent.parent))

import argparse
import requests
from datetime import datetime, timezone
from typing import Dict, List, Any, Optional
from core.gazelle_api_client import GazelleAPIClient
from core.supabase_storage import SupabaseStorage


class DeepBackfillService:
    """Service de restauration historique profonde avec sÃ©curitÃ© anti-effacement."""

    def __init__(self):
        self.api_client = GazelleAPIClient()
        self.storage = SupabaseStorage()

        # Compteurs globaux
        self.total_timeline_synced = 0
        self.total_timeline_errors = 0
        self.total_pianos_synced = 0
        self.total_clients_synced = 0

    def get_existing_timeline_ids(self) -> set:
        """
        RÃ©cupÃ¨re tous les external_id dÃ©jÃ  prÃ©sents dans Supabase.
        Permet la reprise intelligente.

        Returns:
            Set d'external_id dÃ©jÃ  synchronisÃ©s
        """
        print("ğŸ” VÃ©rification des entrÃ©es dÃ©jÃ  synchronisÃ©es...")

        try:
            url = f"{self.storage.api_url}/gazelle_timeline_entries?select=external_id"
            headers = self.storage._get_headers()

            existing_ids = set()
            offset = 0
            limit = 1000

            while True:
                paginated_url = f"{url}&offset={offset}&limit={limit}"
                resp = requests.get(paginated_url, headers=headers)

                if resp.status_code != 200:
                    print(f"âš ï¸  Erreur rÃ©cupÃ©ration IDs existants: {resp.status_code}")
                    return set()

                data = resp.json()
                if not data:
                    break

                for item in data:
                    if item.get('external_id'):
                        existing_ids.add(item['external_id'])

                if len(data) < limit:
                    break

                offset += limit

            print(f"âœ… TrouvÃ© {len(existing_ids)} entrÃ©es dÃ©jÃ  synchronisÃ©es")
            return existing_ids

        except Exception as e:
            print(f"âš ï¸  Erreur lors de la vÃ©rification: {e}")
            return set()

    def backfill_timeline_year(self, year: int, existing_ids: set) -> Dict[str, int]:
        """
        RÃ©cupÃ¨re toutes les timeline entries pour une annÃ©e donnÃ©e.

        Args:
            year: AnnÃ©e Ã  synchroniser (ex: 2024)
            existing_ids: Set des external_id dÃ©jÃ  dans Supabase (reprise intelligente)

        Returns:
            Dict avec 'synced' et 'errors'
        """
        print(f"\n{'='*70}")
        print(f"ğŸ“… ANNÃ‰E {year} - Timeline Entries")
        print(f"{'='*70}")

        # Dates de dÃ©but et fin pour l'annÃ©e
        start_date = f"{year}-01-01T00:00:00Z"
        end_date = f"{year}-12-31T23:59:59Z"

        print(f"ğŸ“ PÃ©riode: {start_date} â†’ {end_date}")

        synced = 0
        errors = 0
        skipped = 0
        cursor = None
        page = 0

        # GraphQL Query avec pagination Relay
        query = """
        query GetTimelineYear($cursor: String, $occurredAtGet: CoreDateTime, $occurredAtLte: CoreDateTime) {
            allTimelineEntries(
                first: 100,
                after: $cursor,
                occurredAtGet: $occurredAtGet,
                occurredAtLte: $occurredAtLte
            ) {
                edges {
                    node {
                        id
                        occurredAt
                        type
                        summary
                        comment
                        client { id }
                        piano { id }
                        invoice { id }
                        estimate { id }
                        user { id }
                    }
                }
                pageInfo {
                    hasNextPage
                    endCursor
                }
            }
        }
        """

        while True:
            page += 1

            try:
                # ExÃ©cuter la query
                variables = {
                    "cursor": cursor,
                    "occurredAtGet": start_date,
                    "occurredAtLte": end_date
                }

                result = self.api_client._execute_query(query, variables)
                entries_data = result.get('allTimelineEntries', {})
                edges = entries_data.get('edges', [])
                page_info = entries_data.get('pageInfo', {})

                if not edges:
                    print(f"   ğŸ“„ Page {page}: 0 entrÃ©es (fin)")
                    break

                print(f"   ğŸ“„ Page {page}: {len(edges)} entrÃ©es rÃ©cupÃ©rÃ©es")

                # Synchroniser chaque entrÃ©e avec UPSERT
                for edge in edges:
                    entry = edge.get('node', {})
                    entry_id = entry.get('id')

                    # REPRISE INTELLIGENTE: Skip si dÃ©jÃ  dans Supabase
                    if entry_id in existing_ids:
                        skipped += 1
                        continue

                    try:
                        # PrÃ©parer le record Supabase
                        record = {
                            'external_id': entry_id,
                            'entry_type': entry.get('type'),
                            'description': entry.get('comment'),
                            'title': entry.get('summary'),
                            'occurred_at': entry.get('occurredAt'),
                            'entity_id': entry.get('client', {}).get('id') if entry.get('client') else None,
                            'piano_id': entry.get('piano', {}).get('id') if entry.get('piano') else None,
                            'user_id': entry.get('user', {}).get('id') if entry.get('user') else None,
                            'invoice_id': entry.get('invoice', {}).get('id') if entry.get('invoice') else None,
                            'estimate_id': entry.get('estimate', {}).get('id') if entry.get('estimate') else None
                        }

                        # UPSERT SÃ‰CURISÃ‰ - on_conflict Ã©vite les doublons
                        url = f"{self.storage.api_url}/gazelle_timeline_entries?on_conflict=external_id"
                        headers = self.storage._get_headers()
                        headers['Prefer'] = 'resolution=merge-duplicates'

                        resp = requests.post(url, headers=headers, json=record)

                        if resp.status_code in [200, 201]:
                            synced += 1
                            existing_ids.add(entry_id)  # Ajouter au set pour Ã©viter duplicata
                        else:
                            errors += 1
                            if errors <= 5:  # Afficher seulement les 5 premiÃ¨res erreurs
                                print(f"   âš ï¸  Erreur entry {entry_id}: {resp.status_code}")

                    except Exception as e:
                        errors += 1
                        if errors <= 5:
                            print(f"   âŒ Exception entry {entry_id}: {str(e)[:50]}")

                # VÃ©rifier si on doit continuer
                has_next = page_info.get('hasNextPage', False)
                if not has_next:
                    print(f"   âœ… Fin de l'annÃ©e (derniÃ¨re page)")
                    break

                cursor = page_info.get('endCursor')

            except Exception as e:
                print(f"   âŒ Erreur page {page}: {e}")
                errors += len(edges) if edges else 0
                break

        print(f"\nğŸ“Š AnnÃ©e {year} - RÃ©sumÃ©:")
        print(f"   âœ… SynchronisÃ©es: {synced}")
        print(f"   â­ï¸  SautÃ©es (dÃ©jÃ  prÃ©sentes): {skipped}")
        print(f"   âŒ Erreurs: {errors}")

        self.total_timeline_synced += synced
        self.total_timeline_errors += errors

        return {'synced': synced, 'errors': errors, 'skipped': skipped}

    def backfill_pianos(self) -> int:
        """
        RÃ©cupÃ¨re TOUS les pianos (historique complet).

        Returns:
            Nombre de pianos synchronisÃ©s
        """
        print(f"\n{'='*70}")
        print(f"ğŸ¹ SYNCHRONISATION COMPLÃˆTE DES PIANOS")
        print(f"{'='*70}")

        try:
            # Utiliser la mÃ©thode existante du syncer
            from modules.sync_gazelle.sync_to_supabase import GazelleToSupabaseSync
            syncer = GazelleToSupabaseSync()

            count = syncer.sync_pianos()
            self.total_pianos_synced = count

            print(f"âœ… Pianos synchronisÃ©s: {count}")
            return count

        except Exception as e:
            print(f"âŒ Erreur sync pianos: {e}")
            return 0

    def backfill_clients(self) -> int:
        """
        RÃ©cupÃ¨re TOUS les clients (historique complet).

        Returns:
            Nombre de clients synchronisÃ©s
        """
        print(f"\n{'='*70}")
        print(f"ğŸ¢ SYNCHRONISATION COMPLÃˆTE DES CLIENTS")
        print(f"{'='*70}")

        try:
            # Utiliser la mÃ©thode existante du syncer
            from modules.sync_gazelle.sync_to_supabase import GazelleToSupabaseSync
            syncer = GazelleToSupabaseSync()

            count = syncer.sync_clients()
            self.total_clients_synced = count

            print(f"âœ… Clients synchronisÃ©s: {count}")
            return count

        except Exception as e:
            print(f"âŒ Erreur sync clients: {e}")
            return 0

    def run_full_backfill(self, start_year: int = 2016, end_year: int = 2026):
        """
        ExÃ©cute la restauration historique complÃ¨te.

        Args:
            start_year: PremiÃ¨re annÃ©e Ã  synchroniser
            end_year: DerniÃ¨re annÃ©e Ã  synchroniser
        """
        print("\n" + "="*70)
        print("ğŸš€ RESTAURATION HISTORIQUE PROFONDE GAZELLE")
        print("="*70)
        print(f"PÃ©riode: {start_year} - {end_year}")
        print(f"Mode: UPSERT sÃ©curisÃ© (pas de suppression)")
        print(f"DÃ©marrage: {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')}")
        print("="*70)

        start_time = datetime.now(timezone.utc)

        # 1. Synchroniser les clients (requis pour les relations)
        print("\nğŸ“ Ã‰TAPE 1/3: Clients")
        self.backfill_clients()

        # 2. Synchroniser les pianos (requis pour les relations)
        print("\nğŸ“ Ã‰TAPE 2/3: Pianos")
        self.backfill_pianos()

        # 3. RÃ©cupÃ©rer les IDs dÃ©jÃ  synchronisÃ©s (REPRISE INTELLIGENTE)
        print("\nğŸ“ Ã‰TAPE 3a/3: Reprise intelligente")
        existing_ids = self.get_existing_timeline_ids()

        # 4. Synchroniser les timeline entries annÃ©e par annÃ©e
        print("\nğŸ“ Ã‰TAPE 3b/3: Timeline Entries (annÃ©e par annÃ©e)")

        for year in range(start_year, end_year + 1):
            self.backfill_timeline_year(year, existing_ids)

        # RÃ©sumÃ© final
        end_time = datetime.now(timezone.utc)
        duration = (end_time - start_time).total_seconds()

        print("\n" + "="*70)
        print("âœ… RESTAURATION HISTORIQUE TERMINÃ‰E")
        print("="*70)
        print(f"ğŸ“Š RÃ©sumÃ© global:")
        print(f"   Clients synchronisÃ©s: {self.total_clients_synced}")
        print(f"   Pianos synchronisÃ©s: {self.total_pianos_synced}")
        print(f"   Timeline synchronisÃ©es: {self.total_timeline_synced}")
        print(f"   Timeline erreurs: {self.total_timeline_errors}")
        print(f"\nâ±ï¸  DurÃ©e totale: {duration:.1f} secondes")
        print(f"ğŸ• Fin: {end_time.strftime('%Y-%m-%d %H:%M:%S UTC')}")
        print("="*70)


def main():
    """Point d'entrÃ©e du script."""
    parser = argparse.ArgumentParser(
        description="Restauration historique profonde Gazelle (2016-2026)"
    )
    parser.add_argument(
        '--start-year',
        type=int,
        default=2016,
        help='PremiÃ¨re annÃ©e Ã  synchroniser (dÃ©faut: 2016)'
    )
    parser.add_argument(
        '--end-year',
        type=int,
        default=2026,
        help='DerniÃ¨re annÃ©e Ã  synchroniser (dÃ©faut: 2026)'
    )

    args = parser.parse_args()

    # Validation
    if args.start_year > args.end_year:
        print("âŒ Erreur: start-year doit Ãªtre <= end-year")
        sys.exit(1)

    if args.start_year < 2016 or args.end_year > 2026:
        print("âŒ Erreur: Les annÃ©es doivent Ãªtre entre 2016 et 2026")
        sys.exit(1)

    # ExÃ©cution
    service = DeepBackfillService()
    service.run_full_backfill(
        start_year=args.start_year,
        end_year=args.end_year
    )


if __name__ == '__main__':
    main()
