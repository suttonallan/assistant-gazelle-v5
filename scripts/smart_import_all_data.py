#!/usr/bin/env python3
"""
smart_import_all_data.py - Import intelligent et massif Gazelle ‚Üí Supabase

Triple Flux (GraphQL):
- allInvoices ‚Üí gazelle_invoices
- allEstimates ‚Üí gazelle_estimates  
- allTimelineEntries (depuis 2016) ‚Üí gazelle_timeline_entries

Filtre Anti-Bruit Strict:
- Ignore Mailchimp, emails ouverts, cr√©ation/suppression rendez-vous
- Garde seulement les entr√©es de haute valeur technique

Extraction de Mesures:
- Regex pour humidit√© (45%), temp√©rature (23¬∞), fr√©quence (440Hz)
- Stocke dans colonnes d√©di√©es

Conservation de l'Existant:
- UPSERT pour √©viter doublons
- Utilise GazelleAPIClient et SupabaseStorage
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

import re
import time
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timezone
from collections import defaultdict

from core.gazelle_api_client import GazelleAPIClient
from core.supabase_storage import SupabaseStorage
from supabase import create_client


class SmartImport:
    """Import intelligent avec filtrage qualit√©."""
    
    # Patterns anti-bruit
    NOISE_PATTERNS = [
        r'Mailchimp',
        r'Email opened',
        r'Email delivered',
        r'Email sent',
        r'A cr√©√© un rendez-vous',
        r'Suppression d\'un rendez-vous',
        r'Appointment created',
        r'Appointment deleted',
        r'Email bounced',
        r'Email clicked',
    ]
    
    def __init__(self, dry_run: bool = False, delay: float = 0.5):
        """
        Initialise l'import.
        
        Args:
            dry_run: Si True, affiche sans √©crire dans Supabase
            delay: D√©lai en secondes entre requ√™tes API (d√©faut: 0.5s)
        """
        print("üî¨ Initialisation Smart Import...")
        self.dry_run = dry_run
        self.delay = delay
        self.stats = {
            'invoices': {'success': 0, 'errors': 0, 'filtered': 0},
            'estimates': {'success': 0, 'errors': 0, 'filtered': 0},
            'timeline': {'success': 0, 'errors': 0, 'filtered': 0, 'noise_filtered': 0}
        }
        
        if dry_run:
            print("‚ö†Ô∏è  MODE DRY-RUN: Aucune √©criture dans Supabase")
        
        print(f"‚è±Ô∏è  D√©lai entre requ√™tes: {delay}s")
        self.api_client = GazelleAPIClient()
        self.storage = SupabaseStorage(silent=True)
        self.supabase = create_client(self.storage.supabase_url, self.storage.supabase_key)
        print("‚úÖ Smart Import initialis√©")
    
    def is_valuable(self, entry: Dict[str, Any]) -> bool:
        """
        Filtre anti-bruit strict: d√©termine si une entr√©e est de haute valeur.
        
        Rejette:
        - Administratif (Mailchimp, emails ouverts)
        - Marketing (campagnes email)
        - Logistique basique (cr√©ation/suppression rendez-vous sans contenu)
        """
        # Ignorer les entr√©es sans contenu
        comment = entry.get('comment', '') or ''
        summary = entry.get('summary', '') or ''
        combined_text = f"{summary} {comment}".strip().lower()
        
        if not combined_text:
            # Rendez-vous termin√© sans commentaire = pas de valeur
            entry_type = entry.get('type', '').upper()
            if entry_type in ['APPOINTMENT', 'APPOINTMENT_COMPLETION']:
                return False
            return True  # Autres types sans texte peuvent √™tre gard√©s
        
        # V√©rifier patterns anti-bruit
        for pattern in self.NOISE_PATTERNS:
            if re.search(pattern, combined_text, re.IGNORECASE):
                return False
        
        return True
    
    def _map_entry_type(self, gazelle_type: str) -> str:
        """
        Mappe les types Gazelle vers les types valides de la contrainte Supabase.
        
        Contrainte SQL accepte:
        - APPOINTMENT, CONTACT_EMAIL, NOTE, APPOINTMENT_COMPLETION,
        - SYSTEM_NOTIFICATION, SERVICE_ENTRY_MANUAL, PIANO_MEASUREMENT,
        - INVOICE_PAYMENT, ERROR_MESSAGE
        """
        type_mapping = {
            # Types d√©j√† valides
            'APPOINTMENT': 'APPOINTMENT',
            'CONTACT_EMAIL': 'CONTACT_EMAIL',
            'NOTE': 'NOTE',
            'APPOINTMENT_COMPLETION': 'APPOINTMENT_COMPLETION',
            'SYSTEM_NOTIFICATION': 'SYSTEM_NOTIFICATION',
            'SERVICE_ENTRY_MANUAL': 'SERVICE_ENTRY_MANUAL',
            'PIANO_MEASUREMENT': 'PIANO_MEASUREMENT',
            'INVOICE_PAYMENT': 'INVOICE_PAYMENT',
            'ERROR_MESSAGE': 'ERROR_MESSAGE',
            
            # Mapping des types automatis√©s vers types valides
            'CONTACT_EMAIL_AUTOMATED': 'CONTACT_EMAIL',
            'SERVICE_ENTRY_AUTOMATED': 'SERVICE_ENTRY_MANUAL',
            'SYSTEM_MESSAGE': 'SYSTEM_NOTIFICATION',
            
            # Mapping des types factures/soumissions
            'INVOICE': 'INVOICE_PAYMENT',
            'INVOICE_LOG': 'NOTE',
            'ESTIMATE': 'NOTE',
            'ESTIMATE_LOG': 'NOTE',
        }
        
        return type_mapping.get(gazelle_type, 'NOTE')  # D√©faut: NOTE
    
    def extract_measurements(self, text: str) -> Dict[str, Optional[float]]:
        """
        Extrait les mesures depuis le texte:
        - Humidit√©: 45%, humidit√© 45
        - Temp√©rature: 23¬∞, 23C, 23¬∞C
        - Fr√©quence: 440Hz, 440 Hz
        """
        if not text:
            return {'humidity': None, 'temperature': None, 'frequency': None}
        
        measurements = {'humidity': None, 'temperature': None, 'frequency': None}
        text_lower = text.lower()
        
        # Humidit√©: 45%, humidit√© 45, RH 45%
        humidity_patterns = [
            r'humidit[√©e].*?(\d+)\s*%',
            r'rh.*?(\d+)\s*%',
            r'(\d+)\s*%.*?humidit',
        ]
        for pattern in humidity_patterns:
            match = re.search(pattern, text_lower, re.IGNORECASE)
            if match:
                try:
                    measurements['humidity'] = float(match.group(1))
                    break
                except:
                    pass
        
        # Temp√©rature: 23¬∞, 23C, 23¬∞C, temp√©rature 23
        temp_patterns = [
            r'temp[√©e]rature.*?(\d+)',
            r'(\d+)\s*[¬∞C]',
            r'(\d+)\s*celsius',
        ]
        for pattern in temp_patterns:
            match = re.search(pattern, text_lower, re.IGNORECASE)
            if match:
                try:
                    temp = float(match.group(1))
                    # Si > 100, probablement Fahrenheit
                    if temp > 100:
                        temp = (temp - 32) * 5 / 9
                    measurements['temperature'] = temp
                    break
                except:
                    pass
        
        # Fr√©quence: 440Hz, 440 Hz, 440.5Hz
        freq_pattern = r'(\d+(?:\.\d+)?)\s*Hz'
        match = re.search(freq_pattern, text, re.IGNORECASE)
        if match:
            try:
                measurements['frequency'] = float(match.group(1))
            except:
                pass
        
        return measurements
    
    def import_invoices(self) -> Dict[str, int]:
        """Importe les factures (allInvoices) vers gazelle_invoices."""
        print("\n" + "="*70)
        print("üìÑ IMPORT FACTURES (allInvoices ‚Üí gazelle_invoices)")
        if self.dry_run:
            print("‚ö†Ô∏è  MODE DRY-RUN - Aucune √©criture")
        print("="*70)
        
        try:
            invoices = self.api_client.get_invoices(limit=10000)
            print(f"‚úÖ {len(invoices)} factures r√©cup√©r√©es depuis Gazelle")
            
            for invoice in invoices:
                try:
                    invoice_id = invoice.get('id')
                    client_id = invoice.get('clientId')
                    
                    # Pr√©parer record Supabase
                    record = {
                        'external_id': invoice_id,
                        'client_external_id': client_id,
                        'invoice_number': invoice.get('number'),
                        'invoice_date': invoice.get('invoiceDate'),
                        'status': invoice.get('status'),
                        'subtotal': invoice.get('subTotal'),
                        'total': invoice.get('total'),
                        'due_date': invoice.get('dueOn'),
                        'notes': invoice.get('notes'),
                        'metadata': invoice  # JSON complet pour r√©f√©rence
                    }
                    
                    # Nettoyer None
                    record = {k: v for k, v in record.items() if v is not None}
                    
                    if self.dry_run:
                        print(f"  [DRY-RUN] UPSERT: {invoice.get('number', invoice_id)}")
                        self.stats['invoices']['success'] += 1
                    else:
                        # UPSERT
                        result = self.supabase.table('gazelle_invoices')\
                            .upsert(record, on_conflict='external_id')\
                            .execute()
                        
                        if result.data:
                            print(f"  [INVOICES] OK: {invoice.get('number', invoice_id)}")
                            self.stats['invoices']['success'] += 1
                    
                except Exception as e:
                    print(f"  [INVOICES] ERREUR: {invoice.get('id', 'unknown')} - {e}")
                    self.stats['invoices']['errors'] += 1
                    # Continue - atomicit√©: une erreur ne bloque pas le reste
            
            return {'total': len(invoices), 'imported': self.stats['invoices']['success']}
            
        except Exception as e:
            print(f"‚ùå Erreur import factures: {e}")
            import traceback
            traceback.print_exc()
            return {'total': 0, 'imported': 0}
    
    def import_estimates(self) -> Dict[str, int]:
        """Importe les soumissions (allEstimates) vers gazelle_estimates."""
        print("\n" + "="*70)
        print("üìã IMPORT SOUMISSIONS (allEstimates ‚Üí gazelle_estimates)")
        if self.dry_run:
            print("‚ö†Ô∏è  MODE DRY-RUN - Aucune √©criture")
        print("="*70)
        
        try:
            # Note: get_estimates() doit exister dans GazelleAPIClient
            # Si absent, cr√©er la m√©thode ou utiliser query directe
            query = """
            query {
                allEstimates(first: 10000) {
                    nodes {
                        id
                        clientId
                        number
                        estimateDate
                        status
                        total
                        notes
                    }
                }
            }
            """
            
            time.sleep(self.delay)  # Pagination s√©curis√©e
            result = self.api_client._execute_query(query)
            estimates = result.get('data', {}).get('allEstimates', {}).get('nodes', [])
            print(f"‚úÖ {len(estimates)} soumissions r√©cup√©r√©es depuis Gazelle")
            
            for estimate in estimates:
                try:
                    estimate_id = estimate.get('id')
                    client_id = estimate.get('clientId')
                    
                    record = {
                        'external_id': estimate_id,
                        'client_external_id': client_id,
                        'estimate_number': estimate.get('number'),
                        'estimate_date': estimate.get('estimateDate'),
                        'status': estimate.get('status'),
                        'total': estimate.get('total'),
                        'notes': estimate.get('notes'),
                        'metadata': estimate
                    }
                    
                    record = {k: v for k, v in record.items() if v is not None}
                    
                    if self.dry_run:
                        print(f"  [DRY-RUN] UPSERT: {estimate.get('number', estimate_id)}")
                        self.stats['estimates']['success'] += 1
                    else:
                        # UPSERT
                        result = self.supabase.table('gazelle_estimates')\
                            .upsert(record, on_conflict='external_id')\
                            .execute()
                        
                        if result.data:
                            print(f"  [ESTIMATES] OK: {estimate.get('number', estimate_id)}")
                            self.stats['estimates']['success'] += 1
                    
                except Exception as e:
                    print(f"  [ESTIMATES] ERREUR: {estimate.get('id', 'unknown')} - {e}")
                    self.stats['estimates']['errors'] += 1
                    # Continue - atomicit√©
            
            return {'total': len(estimates), 'imported': self.stats['estimates']['success']}
            
        except Exception as e:
            print(f"‚ùå Erreur import soumissions: {e}")
            import traceback
            traceback.print_exc()
            return {'total': 0, 'imported': 0}
    
    def import_timeline(self, since_date: str = None) -> Dict[str, int]:
        """
        Importe la timeline en mode FEN√äTRE GLISSANTE (7 derniers jours par d√©faut).

        Applique le filtre anti-bruit strict et extraction de mesures.
        
        Args:
            since_date: Date de d√©but (ISO format). Si None, utilise 7 jours en arri√®re.
        """
        # Mode fen√™tre glissante: 7 derniers jours par d√©faut
        if since_date is None:
            from datetime import datetime, timedelta
            cutoff = datetime.now() - timedelta(days=7)
            since_date = cutoff.strftime('%Y-%m-%dT%H:%M:%SZ')
            print("\n" + "="*70)
            print(f"üìù IMPORT TIMELINE - MODE FEN√äTRE GLISSANTE (7 derniers jours)")
            print("="*70)
        else:
            print("\n" + "="*70)
            print(f"üìù IMPORT TIMELINE (allTimelineEntries depuis {since_date})")
            print("="*70)
        
        try:
            # R√©cup√©rer toutes les entr√©es depuis 2016 avec pagination s√©curis√©e
            # Note: get_timeline_entries pagine automatiquement, mais on ajoute un d√©lai
            # pour les requ√™tes multiples si n√©cessaire
            entries = self.api_client.get_timeline_entries(limit=None, since_date=since_date)
            print(f"‚úÖ {len(entries)} entr√©es timeline r√©cup√©r√©es depuis Gazelle")
            
            # Filtre anti-bruit strict
            valuable_entries = []
            rejected_count = 0
            
            for entry in entries:
                if self.is_valuable(entry):
                    valuable_entries.append(entry)
                else:
                    rejected_count += 1
                    self.stats['timeline']['noise_filtered'] += 1
            
            print(f"üìä Filtre qualit√©: {len(valuable_entries)}/{len(entries)} entr√©es de haute valeur")
            print(f"   ‚Üí {rejected_count} entr√©es rejet√©es (anti-bruit)")
            
            # Audit Mode: R√©sum√© par client
            client_stats = defaultdict(int)
            for entry in valuable_entries:
                client = entry.get('client', {})
                client_id = client.get('id') if client else None
                if client_id:
                    client_stats[client_id] += 1
            
            if client_stats:
                print(f"\nüìã R√©partition par client (entr√©es de haute valeur):")
                for client_id, count in list(client_stats.items())[:10]:
                    print(f"   {client_id}: {count} entr√©es")
                if len(client_stats) > 10:
                    print(f"   ... et {len(client_stats) - 10} autres clients")
            
            # Import avec extraction de mesures
            for entry in valuable_entries:
                try:
                    # D√©lai entre chaque import pour ne pas surcharger Supabase/Cloudflare
                    # Note: Pagination Gazelle est g√©r√©e par get_timeline_entries
                    # Ce d√©lai est pour l'√©criture Supabase uniquement
                    if self.delay > 0 and not self.dry_run:
                        time.sleep(self.delay)
                    external_id = entry.get('id')
                    entry_type = entry.get('type', 'NOTE')
                    
                    # R√©cup√©rer texte combin√© pour extraction mesures
                    summary = entry.get('summary', '') or ''
                    comment = entry.get('comment', '') or ''
                    combined_text = f"{summary} {comment}".strip()
                    
                    # Extraire mesures
                    measurements = self.extract_measurements(combined_text)
                    
                    # Parser dates
                    occurred_at_raw = entry.get('occurredAt')
                    occurred_at_iso = None
                    if occurred_at_raw:
                        try:
                            dt = datetime.fromisoformat(occurred_at_raw.replace('Z', '+00:00'))
                            if dt.tzinfo is None:
                                dt = dt.replace(tzinfo=timezone.utc)
                            occurred_at_iso = dt.isoformat()
                        except:
                            occurred_at_iso = occurred_at_raw
                    
                    # Construire record Supabase
                    client_obj = entry.get('client', {})
                    piano_obj = entry.get('piano', {})
                    user_obj = entry.get('user', {})
                    
                    # Mapping des types Gazelle vers types valides Supabase
                    # Contrainte SQL accepte: APPOINTMENT, CONTACT_EMAIL, NOTE, APPOINTMENT_COMPLETION,
                    # SYSTEM_NOTIFICATION, SERVICE_ENTRY_MANUAL, PIANO_MEASUREMENT, INVOICE_PAYMENT, ERROR_MESSAGE
                    entry_type_gazelle = entry_type.upper() if entry_type else 'NOTE'
                    entry_type_mapped = self._map_entry_type(entry_type_gazelle)
                    
                    # Sch√©ma v5: utiliser les m√™mes colonnes que sync_to_supabase.py
                    record = {
                        'external_id': external_id,
                        'client_id': client_obj.get('id') if client_obj else None,
                        'piano_id': piano_obj.get('id') if piano_obj else None,
                        'user_id': user_obj.get('id') if user_obj else None,
                        'occurred_at': occurred_at_iso,
                        'entry_type': entry_type_mapped,  # Type mapp√© vers valeurs valides
                        'title': summary[:500] if summary else None,
                        'description': comment[:2000] if comment else None,
                    }
                    
                    # Ajouter mesures si extraites
                    metadata = {}
                    if measurements['humidity'] is not None:
                        metadata['humidity'] = measurements['humidity']
                    if measurements['temperature'] is not None:
                        metadata['temperature'] = measurements['temperature']
                    if measurements['frequency'] is not None:
                        metadata['frequency'] = measurements['frequency']
                    
                    if metadata:
                        record['metadata'] = metadata
                    
                    # Nettoyer None
                    record = {k: v for k, v in record.items() if v is not None and v != ''}
                    
                    if self.dry_run:
                        # Afficher label simple
                        label = comment[:50] if comment else summary[:50] or entry_type
                        print(f"  [DRY-RUN] UPSERT: {label}")
                        self.stats['timeline']['success'] += 1
                    else:
                        # UPSERT
                        result = self.supabase.table('gazelle_timeline_entries')\
                            .upsert(record, on_conflict='external_id')\
                            .execute()
                        
                        if result.data:
                            # Afficher label simple
                            label = comment[:50] if comment else summary[:50] or entry_type
                            print(f"  [TIMELINE] OK: {label}")
                            self.stats['timeline']['success'] += 1
                    
                except Exception as e:
                    entry_id = entry.get('id', 'unknown')
                    print(f"  [TIMELINE] ERREUR: {entry_id} - {e}")
                    self.stats['timeline']['errors'] += 1
                    # Continue - atomicit√©: une erreur ne bloque pas le reste
            
            return {
                'total': len(entries),
                'valuable': len(valuable_entries),
                'imported': self.stats['timeline']['success']
            }
            
        except Exception as e:
            print(f"‚ùå Erreur import timeline: {e}")
            import traceback
            traceback.print_exc()
            return {'total': 0, 'valuable': 0, 'imported': 0}
    
    def run_all(self, since_date: str = "2016-01-01T00:00:00Z"):
        """Ex√©cute l'import complet des 3 flux."""
        print("\n" + "="*70)
        print("üöÄ SMART IMPORT - TRIPLE FLUX COMPLET")
        print("="*70)
        
        results = {
            'invoices': self.import_invoices(),
            'estimates': self.import_estimates(),
            'timeline': self.import_timeline(since_date=since_date)
        }
        
        # R√©sum√© final avec logs clairs
        print("\n" + "="*70)
        print("üìä R√âSUM√â FINAL")
        print("="*70)
        
        # Factures
        inv = self.stats['invoices']
        print(f"üìÑ FACTURES:")
        print(f"   Succ√®s: {inv['success']} | √âchecs: {inv['errors']} | Filtr√©s: {inv['filtered']}")
        
        # Soumissions
        est = self.stats['estimates']
        print(f"üìã SOUMISSIONS:")
        print(f"   Succ√®s: {est['success']} | √âchecs: {est['errors']} | Filtr√©s: {est['filtered']}")
        
        # Timeline
        tl = self.stats['timeline']
        print(f"üìù TIMELINE:")
        print(f"   Succ√®s: {tl['success']} | √âchecs: {tl['errors']} | Filtr√©s (bruit): {tl['noise_filtered']}")
        print(f"   Total r√©cup√©r√©: {results['timeline']['total']}")
        print(f"   Haute valeur: {results['timeline']['valuable']}")
        
        if self.dry_run:
            print("\n‚ö†Ô∏è  MODE DRY-RUN - Aucune donn√©e √©crite dans Supabase")
        
        print("="*70)


def main():
    """Point d'entr√©e principal."""
    import argparse
    
    parser = argparse.ArgumentParser(description="Smart Import - Import intelligent Gazelle ‚Üí Supabase")
    parser.add_argument('--since', type=str, default="2016-01-01T00:00:00Z",
                       help='Date de d√©but pour timeline (format ISO)')
    parser.add_argument('--invoices-only', action='store_true', help='Importer seulement les factures')
    parser.add_argument('--estimates-only', action='store_true', help='Importer seulement les soumissions')
    parser.add_argument('--timeline-only', action='store_true', help='Importer seulement la timeline')
    parser.add_argument('--dry-run', action='store_true', 
                       help='Mode dry-run: affiche sans √©crire dans Supabase')
    parser.add_argument('--delay', type=float, default=0.5,
                       help='D√©lai en secondes entre requ√™tes (d√©faut: 0.5s)')
    args = parser.parse_args()
    
    importer = SmartImport(dry_run=args.dry_run, delay=args.delay)
    
    if args.invoices_only:
        importer.import_invoices()
    elif args.estimates_only:
        importer.import_estimates()
    elif args.timeline_only:
        importer.import_timeline(since_date=args.since)
    else:
        # Import complet
        importer.run_all(since_date=args.since)


if __name__ == '__main__':
    main()
